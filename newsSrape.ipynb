{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The National Labor Relations Board last week accused Apple of trying to prevent employees from discussing pay equity and pressuring an engineer who attempted to circulate a survey about wages to quit.\n",
      "These actions by the company, the complaint said, unlawfully forced Scarlett to quit.\n",
      "Apple managers allegedly threatened other employees who posted on social media and in Slack and spoke to the press about workplace concerns, according to the complaint.\n",
      "The NLRB is also looking to force Apple to reinstate Scarlett, compensate her for lost pay and issue an apology letter.\n",
      "The complaints by federal regulators highlight ongoing turmoil around organizing efforts by Apple employees both at the iPhone maker's corporate headquarters and at retail stores.\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "import nltk\n",
    "\n",
    "url = 'https://www.yahoo.com/news/labor-board-accuses-apple-suppressing-222846876.html'\n",
    "article = Article(url)\n",
    "\n",
    "try:\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()  # Run NLP after parsing\n",
    "\n",
    "    # Print results\n",
    "    print(\"Summary:\", article.summary)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tesla_news(url):\n",
    "    \"\"\"\n",
    "    Scrapes Tesla news from the given Yahoo Finance URL.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the Yahoo Finance page for Tesla news.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with columns 'title', 'summary', and 'date'.\n",
    "    \"\"\"\n",
    "\n",
    "    paper = newspaper.build(url)\n",
    "    articles = paper.articles\n",
    "\n",
    "    data = []\n",
    "    n = 0\n",
    "    for article in articles:\n",
    "        if n > 30:\n",
    "            break\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        data.append({'title': article.title,\n",
    "                     'summary': article.summary,\n",
    "                     'date': article.publish_date})\n",
    "        print(article.publish_date)\n",
    "        n += 1\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "ArticleException",
     "evalue": "Article `download()` failed with HTTPSConnectionPool(host='tw.news.yahoo.com', port=443): Max retries exceeded with url: /%E5%B0%8F%E4%BA%8C%E6%95%B8%E5%AD%B8%E8%80%83%E5%80%92%E5%AE%B6%E9%95%B7%E4%BA%86-6-9-54-%E8%A2%AB%E6%89%A3%E5%88%86-080821085.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001B905474AA0>, 'Connection to tw.news.yahoo.com timed out. (connect timeout=7)')) on URL https://tw.news.yahoo.com/%E5%B0%8F%E4%BA%8C%E6%95%B8%E5%AD%B8%E8%80%83%E5%80%92%E5%AE%B6%E9%95%B7%E4%BA%86-6-9-54-%E8%A2%AB%E6%89%A3%E5%88%86-080821085.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArticleException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Replace with the actual Yahoo Finance URL for Tesla news\u001b[39;00m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://finance.yahoo.com/news/tesla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_tesla_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesla_news.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[57], line 21\u001b[0m, in \u001b[0;36mscrape_tesla_news\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     20\u001b[0m article\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m---> 21\u001b[0m \u001b[43marticle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m article\u001b[38;5;241m.\u001b[39mnlp()\n\u001b[0;32m     23\u001b[0m data\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39mtitle,\n\u001b[0;32m     24\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39msummary,\n\u001b[0;32m     25\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: article\u001b[38;5;241m.\u001b[39mpublish_date})\n",
      "File \u001b[1;32mc:\\Users\\mamin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\newspaper\\article.py:191\u001b[0m, in \u001b[0;36mArticle.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow_if_not_downloaded_verbose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_parser()\u001b[38;5;241m.\u001b[39mfromstring(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_doc \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc)\n",
      "File \u001b[1;32mc:\\Users\\mamin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\newspaper\\article.py:531\u001b[0m, in \u001b[0;36mArticle.throw_if_not_downloaded_verbose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ArticleException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must `download()` an article first!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_state \u001b[38;5;241m==\u001b[39m ArticleDownloadState\u001b[38;5;241m.\u001b[39mFAILED_RESPONSE:\n\u001b[1;32m--> 531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ArticleException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArticle `download()` failed with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m on URL \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    532\u001b[0m           (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_exception_msg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl))\n",
      "\u001b[1;31mArticleException\u001b[0m: Article `download()` failed with HTTPSConnectionPool(host='tw.news.yahoo.com', port=443): Max retries exceeded with url: /%E5%B0%8F%E4%BA%8C%E6%95%B8%E5%AD%B8%E8%80%83%E5%80%92%E5%AE%B6%E9%95%B7%E4%BA%86-6-9-54-%E8%A2%AB%E6%89%A3%E5%88%86-080821085.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001B905474AA0>, 'Connection to tw.news.yahoo.com timed out. (connect timeout=7)')) on URL https://tw.news.yahoo.com/%E5%B0%8F%E4%BA%8C%E6%95%B8%E5%AD%B8%E8%80%83%E5%80%92%E5%AE%B6%E9%95%B7%E4%BA%86-6-9-54-%E8%A2%AB%E6%89%A3%E5%88%86-080821085.html"
     ]
    }
   ],
   "source": [
    "# Replace with the actual Yahoo Finance URL for Tesla news\n",
    "url = \"https://finance.yahoo.com/news/tesla\"\n",
    "\n",
    "df = scrape_tesla_news(url)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('tesla_news.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
