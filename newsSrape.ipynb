{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The National Labor Relations Board last week accused Apple of trying to prevent employees from discussing pay equity and pressuring an engineer who attempted to circulate a survey about wages to quit.\n",
      "Apple managers allegedly threatened other employees who posted on social media and in Slack and spoke to the media about workplace concerns, according to the complaint.\n",
      "I donâ€™t regret standing up to Apple and I will continue to fight for the rights of laborers,\" Scarlett said.\n",
      "The NLRB is also looking to force Apple to reinstate Scarlett, compensate her for lost pay and issue an apology letter.\n",
      "The complaints by federal regulators highlight ongoing turmoil around organizing efforts by Apple employees both at the iPhone maker's corporate headquarters and at retail stores.\n"
     ]
    }
   ],
   "source": [
    "# from newspaper import Article\n",
    "# import nltk\n",
    "\n",
    "# url = 'https://www.yahoo.com/news/labor-board-accuses-apple-suppressing-222846876.html'\n",
    "# article = Article(url)\n",
    "\n",
    "# try:\n",
    "#     article.download()\n",
    "#     article.parse()\n",
    "#     article.nlp()  # Run NLP after parsing\n",
    "\n",
    "#     # Print results\n",
    "#     print(\"Summary:\", article.summary)\n",
    "# except Exception as e:\n",
    "#     print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import newspaper\n",
    "import pandas as pd\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tesla_news(url):\n",
    "    \"\"\"\n",
    "    Scrapes Tesla news from the given Yahoo Finance URL.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the Yahoo Finance page for Tesla news.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with columns 'title', 'summary', and 'date'.\n",
    "    \"\"\"\n",
    "\n",
    "    paper = newspaper.build(url)\n",
    "    articles = paper.articles\n",
    "\n",
    "    data = []\n",
    "    n = 0\n",
    "    for article in articles:\n",
    "        if n > 30:\n",
    "            break\n",
    "        try:   \n",
    "            article.download()\n",
    "            article.parse()\n",
    "            text = article.text\n",
    "            language = detect(text)\n",
    "        except:\n",
    "            print('error occured')\n",
    "\n",
    "        print(language)\n",
    "        if language == \"en\":\n",
    "            print('english')\n",
    "            data.append({'title': article.title,\n",
    "                        'text': text,\n",
    "                        'date': article.publish_date,\n",
    "                        'url': article.url})\n",
    "        n += 1\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr\n",
      "en\n",
      "english\n",
      "en\n",
      "english\n",
      "en\n",
      "english\n",
      "en\n",
      "english\n",
      "en\n",
      "english\n",
      "en\n",
      "english\n",
      "en\n",
      "english\n",
      "de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from c:\\Users\\mamin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\jieba\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\mamin\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.9694051742553711 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko\n",
      "zh-tw\n",
      "ko\n",
      "ko\n",
      "ko\n"
     ]
    },
    {
     "ename": "LangDetectException",
     "evalue": "No features in text.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLangDetectException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Replace with the actual Yahoo Finance URL for Tesla news\u001b[39;00m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://finance.yahoo.com/quote/AAPL/news/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_tesla_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# df.to_csv('tesla_news.csv', index=False)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df\n",
      "Cell \u001b[1;32mIn[32], line 27\u001b[0m, in \u001b[0;36mscrape_tesla_news\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror occured\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m text \u001b[38;5;241m=\u001b[39m article\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 27\u001b[0m language \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(language)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m language \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mamin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langdetect\\detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mamin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langdetect\\detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
      "File \u001b[1;32mc:\\Users\\mamin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langdetect\\detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
      "File \u001b[1;32mc:\\Users\\mamin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langdetect\\detector.py:150\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    148\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_ngrams()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ngrams:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LangDetectException(ErrorCode\u001b[38;5;241m.\u001b[39mCantDetectError, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo features in text.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanglist)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n",
      "\u001b[1;31mLangDetectException\u001b[0m: No features in text."
     ]
    }
   ],
   "source": [
    "# Replace with the actual Yahoo Finance URL for Tesla news\n",
    "url = \"https://finance.yahoo.com/quote/AAPL/news/\"\n",
    "\n",
    "df = scrape_tesla_news(url)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df.to_csv('tesla_news.csv', index=False)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
