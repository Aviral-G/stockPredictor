title,text,url,summary
Thursday's big stock stories: What’s likely to move the market in the next trading session,"A check in monitor is see in the Nvidia office on November 20, 2024 in Austin, Texas.

Stocks @ Night is a daily newsletter delivered after hours, giving you a first look at tomorrow and last look at today. Sign up for free to receive it directly in your inbox.

Here's what CNBC TV's producers were watching as stocks ended Wednesday mixed, and what's on the radar for the next session.",https://www.cnbc.com/2024/11/20/thursdays-big-stock-stories-whats-likely-to-move-the-market.html,"Stocks @ Night is a daily newsletter delivered after hours, giving you a first look at tomorrow and last look at today.Sign up for free to receive it directly in your inbox.Here's what CNBC TV's producers were watching as stocks ended Wednesday mixed, and what's on the radar for the next session."
Investors Flock to SPYI's 12% Distribution Rate,"A check in monitor is see in the Nvidia office on November 20, 2024 in Austin, Texas.

Stocks @ Night is a daily newsletter delivered after hours, giving you a first look at tomorrow and last look at today. Sign up for free to receive it directly in your inbox.

Here's what CNBC TV's producers were watching as stocks ended Wednesday mixed, and what's on the radar for the next session.",https://www.etftrends.com/monthly-income-channel/investors-flock-spyis-12-distribution-rate/,"Stocks @ Night is a daily newsletter delivered after hours, giving you a first look at tomorrow and last look at today.Sign up for free to receive it directly in your inbox.Here's what CNBC TV's producers were watching as stocks ended Wednesday mixed, and what's on the radar for the next session."
"After Revenue Jump, Nvidia CEO Says There's Room to Scale","To hear Jensen Huang tell it, Nvidia — and artificial intelligence (AI) in general — is just getting started. The CEO of the most valuable company in the world didn’t rest his laurels on a 94% year-over-year revenue growth number for Q3 and faced up to several questions about the future of his company as well as the general prospects for AIs growth for the rest of the decade.

“Many AI services are running 24/7, just like any factory,” Huang told the earnings call audience. “We’re going to see this new type of system come online. And I call it [the company’s data centers] an AI factory because that’s really close to what it is. It’s unlike a data center of the past.

“And these fundamental trends are really just beginning. We expect this to happen, this growth, this modernization and the creation of a new industry to go on for several years.”

Huang and CFO Colette Kress clearly feel that the company’s best days are ahead of it, even as analysts question whether or not it can keep up the pace in several areas: large language model (LLM) development, AI usage scale and the torrid revenue growth it has achieved over the past two years.

Their reasons for optimism ranged from consumer adoption rates to the coming explosion of enterprise and industrial AI and the long list of companies that rely on Nvidia data centers and chips (whose manufacturing is outsourced) for their own applications.

By way of background, an AI data center is a specialized facility designed to handle the heavy computational demands of AI workloads, essentially providing the infrastructure needed to train and deploy complex machine learning models and algorithms by processing massive amounts of data using high-performance servers, specialized hardware accelerators, and advanced networking capabilities, all optimized for AI operations. In simpler terms, it’s a data center specifically built to power AI applications at scale.

If there was a theme on the call and in the earnings materials, it was that laundry list of companies from Alphabet to Meta to Microsoft to Oracle to Volvo that are hooked into Nvidia. But when that list wasn’t running, Huang and Kress faced some tough questions from analysts, ranging from scaling for LLM development to a potential controversy about reported overheating issues for the companies seven-chip Blackwell set of GPUs that it is banking its next few years on. For perspective, the company’s Q3 earnings were achieved without shipping any newly designed chips. Blackwell is the new addition, and demand, according to Kress, is “staggering.”

Despite some concerns about a potential slowdown in the scaling of LLMs, Huang maintained that there is still ample opportunity for growth. He emphasized that the scaling of foundation models is “intact and continuing,” citing ongoing advancements in post-training scaling and inference-time scaling.

Post-training scaling, which initially involved reinforcement learning with human feedback, has evolved to incorporate AI feedback and synthetic data generation. Meanwhile, inference-time scaling, demonstrated by OpenAI’s ChatGPT-01, allows for improved answer quality with increased processing time.

Huang expressed optimism about the continued growth of the AI market, driven by the ongoing modernization of data centers and the emergence of generative AI applications. He described the shift from traditional coding to machine learning as a fundamental change that will require companies to upgrade their infrastructure to support AI workloads.

Huang also highlighted the emergence of generative AI, which he likened to the advent of the iPhone, as a completely new capability that will create new market segments and opportunities. He cited examples such as OpenAI, Runway and Harvey, which provide basic intelligence, digital artist intelligence, and legal intelligence, respectively.

Nvidia’s Blackwell architecture is designed to meet the demands of this evolving AI landscape. The company has developed seven custom chips for the Blackwell system, which can be configured for air-cooled or liquid-cooled data centers and support various MVlink and CPU options.

Huang acknowledged the engineering challenges involved in integrating these systems into diverse data center architectures but remained confident in Nvidia’s ability to execute. He cited examples of successful collaborations with major cloud service providers (CSPs) such as Dell, Corweave, Oracle, Microsoft and Google.

Nvidia is also seeing strong growth in the enterprise and industrial AI sectors. The company’s Nvidia AI Enterprise platform is being used by industry leaders to build copilots and agents.

In the industrial AI space, Nvidia’s Omniverse platform is enabling the development and operation of industrial AI and robotics applications. Major manufacturers like Foxconn are adopting Omniverse to accelerate their businesses, automate workflows, and improve operating efficiency.

“The first transformative event is moving from coding that runs on CPUs to machine learning that creates neural networks that runs on GPUs,” Huang said. “The second part of it is generative AI, and we’re now producing a new type of capability that world’s never known, a new market segment that the world’s never had.”",https://www.pymnts.com/earnings/2024/after-posting-94-revenue-jump-nvidia-ceo-says-company-has-room-to-scale/?utm_source=snapi,"But when that list wasn’t running, Huang and Kress faced some tough questions from analysts, ranging from scaling for LLM development to a potential controversy about reported overheating issues for the companies seven-chip Blackwell set of GPUs that it is banking its next few years on.Despite some concerns about a potential slowdown in the scaling of LLMs, Huang maintained that there is still ample opportunity for growth.He cited examples of successful collaborations with major cloud service providers (CSPs) such as Dell, Corweave, Oracle, Microsoft and Google."
Nvidia's supply snags hurting deliveries but mask booming demand,"To hear Jensen Huang tell it, Nvidia — and artificial intelligence (AI) in general — is just getting started. The CEO of the most valuable company in the world didn’t rest his laurels on a 94% year-over-year revenue growth number for Q3 and faced up to several questions about the future of his company as well as the general prospects for AIs growth for the rest of the decade.

“Many AI services are running 24/7, just like any factory,” Huang told the earnings call audience. “We’re going to see this new type of system come online. And I call it [the company’s data centers] an AI factory because that’s really close to what it is. It’s unlike a data center of the past.

“And these fundamental trends are really just beginning. We expect this to happen, this growth, this modernization and the creation of a new industry to go on for several years.”

Huang and CFO Colette Kress clearly feel that the company’s best days are ahead of it, even as analysts question whether or not it can keep up the pace in several areas: large language model (LLM) development, AI usage scale and the torrid revenue growth it has achieved over the past two years.

Their reasons for optimism ranged from consumer adoption rates to the coming explosion of enterprise and industrial AI and the long list of companies that rely on Nvidia data centers and chips (whose manufacturing is outsourced) for their own applications.

By way of background, an AI data center is a specialized facility designed to handle the heavy computational demands of AI workloads, essentially providing the infrastructure needed to train and deploy complex machine learning models and algorithms by processing massive amounts of data using high-performance servers, specialized hardware accelerators, and advanced networking capabilities, all optimized for AI operations. In simpler terms, it’s a data center specifically built to power AI applications at scale.

If there was a theme on the call and in the earnings materials, it was that laundry list of companies from Alphabet to Meta to Microsoft to Oracle to Volvo that are hooked into Nvidia. But when that list wasn’t running, Huang and Kress faced some tough questions from analysts, ranging from scaling for LLM development to a potential controversy about reported overheating issues for the companies seven-chip Blackwell set of GPUs that it is banking its next few years on. For perspective, the company’s Q3 earnings were achieved without shipping any newly designed chips. Blackwell is the new addition, and demand, according to Kress, is “staggering.”

Despite some concerns about a potential slowdown in the scaling of LLMs, Huang maintained that there is still ample opportunity for growth. He emphasized that the scaling of foundation models is “intact and continuing,” citing ongoing advancements in post-training scaling and inference-time scaling.

Post-training scaling, which initially involved reinforcement learning with human feedback, has evolved to incorporate AI feedback and synthetic data generation. Meanwhile, inference-time scaling, demonstrated by OpenAI’s ChatGPT-01, allows for improved answer quality with increased processing time.

Huang expressed optimism about the continued growth of the AI market, driven by the ongoing modernization of data centers and the emergence of generative AI applications. He described the shift from traditional coding to machine learning as a fundamental change that will require companies to upgrade their infrastructure to support AI workloads.

Huang also highlighted the emergence of generative AI, which he likened to the advent of the iPhone, as a completely new capability that will create new market segments and opportunities. He cited examples such as OpenAI, Runway and Harvey, which provide basic intelligence, digital artist intelligence, and legal intelligence, respectively.

Nvidia’s Blackwell architecture is designed to meet the demands of this evolving AI landscape. The company has developed seven custom chips for the Blackwell system, which can be configured for air-cooled or liquid-cooled data centers and support various MVlink and CPU options.

Huang acknowledged the engineering challenges involved in integrating these systems into diverse data center architectures but remained confident in Nvidia’s ability to execute. He cited examples of successful collaborations with major cloud service providers (CSPs) such as Dell, Corweave, Oracle, Microsoft and Google.

Nvidia is also seeing strong growth in the enterprise and industrial AI sectors. The company’s Nvidia AI Enterprise platform is being used by industry leaders to build copilots and agents.

In the industrial AI space, Nvidia’s Omniverse platform is enabling the development and operation of industrial AI and robotics applications. Major manufacturers like Foxconn are adopting Omniverse to accelerate their businesses, automate workflows, and improve operating efficiency.

“The first transformative event is moving from coding that runs on CPUs to machine learning that creates neural networks that runs on GPUs,” Huang said. “The second part of it is generative AI, and we’re now producing a new type of capability that world’s never known, a new market segment that the world’s never had.”",https://www.reuters.com/technology/nvidias-supply-snags-hurting-deliveries-mask-booming-demand-2024-11-21/,"But when that list wasn’t running, Huang and Kress faced some tough questions from analysts, ranging from scaling for LLM development to a potential controversy about reported overheating issues for the companies seven-chip Blackwell set of GPUs that it is banking its next few years on.Despite some concerns about a potential slowdown in the scaling of LLMs, Huang maintained that there is still ample opportunity for growth.He cited examples of successful collaborations with major cloud service providers (CSPs) such as Dell, Corweave, Oracle, Microsoft and Google."
Oil and Natural Gas Technical Analysis: Geopolitical Tensions and Seasonal Demand,"English English Italiano Español Português Deutsch العربية Français

Important Disclaimers The content provided on the website includes general news and publications, our personal analysis and opinions, and contents provided by third parties, which are intended for educational and research purposes only. It does not constitute, and should not be read as, any recommendation or advice to take any action whatsoever, including to make any investment or buy any product. When making any financial decision, you should perform your own due diligence checks, apply your own discretion and consult your competent advisors. The content of the website is not personally directed to you, and we does not take into account your financial situation or needs.The information contained in this website is not necessarily provided in real-time nor is it necessarily accurate. Prices provided herein may be provided by market makers and not by exchanges.Any trading or other financial decision you make shall be at your full responsibility, and you must not rely on any information provided through the website. FX Empire does not provide any warranty regarding any of the information contained in the website, and shall bear no responsibility for any trading losses you might incur as a result of using any information contained in the website.The website may include advertisements and other promotional contents, and FX Empire may receive compensation from third parties in connection with the content. FX Empire does not endorse any third party or recommends using any third party's services, and does not assume responsibility for your use of any such third party's website or services.FX Empire and its employees, officers, subsidiaries and associates, are not liable nor shall they be held liable for any loss or damage resulting from your use of the website or reliance on the information provided on this website. Risk Disclaimers This website includes information about cryptocurrencies, contracts for difference (CFDs) and other financial instruments, and about brokers, exchanges and other entities trading in such instruments. Both cryptocurrencies and CFDs are complex instruments and come with a high risk of losing money. You should carefully consider whether you understand how these instruments work and whether you can afford to take the high risk of losing your money.FX Empire encourages you to perform your own research before making any investment decision, and to avoid investing in any financial instrument which you do not fully understand how it works and what are the risks involved.",https://www.fxempire.com/forecasts/article/oil-and-natural-gas-technical-analysis-geopolitical-tensions-and-seasonal-demand-1477745,"The content of the website is not personally directed to you, and we does not take into account your financial situation or needs.The information contained in this website is not necessarily provided in real-time nor is it necessarily accurate.FX Empire does not provide any warranty regarding any of the information contained in the website, and shall bear no responsibility for any trading losses you might incur as a result of using any information contained in the website.The website may include advertisements and other promotional contents, and FX Empire may receive compensation from third parties in connection with the content.FX Empire does not endorse any third party or recommends using any third party's services, and does not assume responsibility for your use of any such third party's website or services.FX Empire and its employees, officers, subsidiaries and associates, are not liable nor shall they be held liable for any loss or damage resulting from your use of the website or reliance on the information provided on this website."
Oil prices firm as geopolitical tensions raise supply concerns,"English English Italiano Español Português Deutsch العربية Français

Important Disclaimers The content provided on the website includes general news and publications, our personal analysis and opinions, and contents provided by third parties, which are intended for educational and research purposes only. It does not constitute, and should not be read as, any recommendation or advice to take any action whatsoever, including to make any investment or buy any product. When making any financial decision, you should perform your own due diligence checks, apply your own discretion and consult your competent advisors. The content of the website is not personally directed to you, and we does not take into account your financial situation or needs.The information contained in this website is not necessarily provided in real-time nor is it necessarily accurate. Prices provided herein may be provided by market makers and not by exchanges.Any trading or other financial decision you make shall be at your full responsibility, and you must not rely on any information provided through the website. FX Empire does not provide any warranty regarding any of the information contained in the website, and shall bear no responsibility for any trading losses you might incur as a result of using any information contained in the website.The website may include advertisements and other promotional contents, and FX Empire may receive compensation from third parties in connection with the content. FX Empire does not endorse any third party or recommends using any third party's services, and does not assume responsibility for your use of any such third party's website or services.FX Empire and its employees, officers, subsidiaries and associates, are not liable nor shall they be held liable for any loss or damage resulting from your use of the website or reliance on the information provided on this website. Risk Disclaimers This website includes information about cryptocurrencies, contracts for difference (CFDs) and other financial instruments, and about brokers, exchanges and other entities trading in such instruments. Both cryptocurrencies and CFDs are complex instruments and come with a high risk of losing money. You should carefully consider whether you understand how these instruments work and whether you can afford to take the high risk of losing your money.FX Empire encourages you to perform your own research before making any investment decision, and to avoid investing in any financial instrument which you do not fully understand how it works and what are the risks involved.",https://www.reuters.com/business/energy/oil-prices-firm-geopolitical-tensions-raise-supply-concerns-2024-11-21/,"The content of the website is not personally directed to you, and we does not take into account your financial situation or needs.The information contained in this website is not necessarily provided in real-time nor is it necessarily accurate.FX Empire does not provide any warranty regarding any of the information contained in the website, and shall bear no responsibility for any trading losses you might incur as a result of using any information contained in the website.The website may include advertisements and other promotional contents, and FX Empire may receive compensation from third parties in connection with the content.FX Empire does not endorse any third party or recommends using any third party's services, and does not assume responsibility for your use of any such third party's website or services.FX Empire and its employees, officers, subsidiaries and associates, are not liable nor shall they be held liable for any loss or damage resulting from your use of the website or reliance on the information provided on this website."
Oil Rises Amid Ongoing Geopolitical Tensions in Europe,"English English Italiano Español Português Deutsch العربية Français

Important Disclaimers The content provided on the website includes general news and publications, our personal analysis and opinions, and contents provided by third parties, which are intended for educational and research purposes only. It does not constitute, and should not be read as, any recommendation or advice to take any action whatsoever, including to make any investment or buy any product. When making any financial decision, you should perform your own due diligence checks, apply your own discretion and consult your competent advisors. The content of the website is not personally directed to you, and we does not take into account your financial situation or needs.The information contained in this website is not necessarily provided in real-time nor is it necessarily accurate. Prices provided herein may be provided by market makers and not by exchanges.Any trading or other financial decision you make shall be at your full responsibility, and you must not rely on any information provided through the website. FX Empire does not provide any warranty regarding any of the information contained in the website, and shall bear no responsibility for any trading losses you might incur as a result of using any information contained in the website.The website may include advertisements and other promotional contents, and FX Empire may receive compensation from third parties in connection with the content. FX Empire does not endorse any third party or recommends using any third party's services, and does not assume responsibility for your use of any such third party's website or services.FX Empire and its employees, officers, subsidiaries and associates, are not liable nor shall they be held liable for any loss or damage resulting from your use of the website or reliance on the information provided on this website. Risk Disclaimers This website includes information about cryptocurrencies, contracts for difference (CFDs) and other financial instruments, and about brokers, exchanges and other entities trading in such instruments. Both cryptocurrencies and CFDs are complex instruments and come with a high risk of losing money. You should carefully consider whether you understand how these instruments work and whether you can afford to take the high risk of losing your money.FX Empire encourages you to perform your own research before making any investment decision, and to avoid investing in any financial instrument which you do not fully understand how it works and what are the risks involved.",https://www.wsj.com/articles/oil-rises-amid-ongoing-geopolitical-tensions-in-europe-4821c2a3?mod=rss_markets_main,"The content of the website is not personally directed to you, and we does not take into account your financial situation or needs.The information contained in this website is not necessarily provided in real-time nor is it necessarily accurate.FX Empire does not provide any warranty regarding any of the information contained in the website, and shall bear no responsibility for any trading losses you might incur as a result of using any information contained in the website.The website may include advertisements and other promotional contents, and FX Empire may receive compensation from third parties in connection with the content.FX Empire does not endorse any third party or recommends using any third party's services, and does not assume responsibility for your use of any such third party's website or services.FX Empire and its employees, officers, subsidiaries and associates, are not liable nor shall they be held liable for any loss or damage resulting from your use of the website or reliance on the information provided on this website."
Nvidia’s CEO defends his moat as AI labs change how they improve their AI models,"Nvidia raked in more than $19 billion in net income during the last quarter, the company reported on Wednesday, but that did little to assure investors that its rapid growth would continue. On its earnings call, analysts prodded CEO Jensen Huang about how Nvidia would fare if tech companies start using new methods to improve their AI models.

The method that underpins OpenAI’s o1 model, or “test-time scaling,” came up quite a lot. It’s the idea that AI models will give better answers if you give them more time and computing power to “think” through questions. Specifically, it adds more compute to the AI inference phase, which is everything that happens after a user hits enter on their prompt.

Nvidia’s CEO was asked whether he was seeing AI model developers shift over to these new methods and how Nvidia’s older chips would work for AI inference.

Huang indicated that o1, and test-time scaling more broadly, could play a larger role in Nvidia’s business moving forward, calling it “one of the most exciting developments” and “a new scaling law.” Huang did his best to ensure investors that Nvidia is well-positioned for the change.

The Nvidia CEO’s remarks aligned with what Microsoft CEO Satya Nadella said onstage at a Microsoft event on Tuesday: o1 represents a new way for the AI industry to improve its models.

This is a big deal for the chip industry because it places a greater emphasis on AI inference. While Nvidia’s chips are the gold standard for training AI models, there’s a broad set of well-funded startups creating lightning-fast AI inference chips, such as Groq and Cerebras. It could be a more competitive space for Nvidia to operate in.

Despite recent reports that improvements in generative models are slowing, Huang told analysts that AI model developers are still improving their models by adding more compute and data during the pretraining phase.

Anthropic CEO Dario Amodei also said on Wednesday during an onstage interview at the Cerebral Valley summit in San Francisco that he is not seeing a slowdown in model development.

“Foundation model pretraining scaling is intact and it’s continuing,” said Huang on Wednesday. “As you know, this is an empirical law, not a fundamental physical law, but the evidence is that it continues to scale. What we’re learning, however, is that it’s not enough.”

That’s certainly what Nvidia investors wanted to hear, since the chipmaker’s stock has soared more than 180% in 2024 by selling the AI chips that OpenAI, Google, and Meta train their models on. However, Andreessen Horowitz partners and several other AI executives have previously said that these methods are already starting to show diminishing returns.

Huang noted that most of Nvidia’s computing workloads today are around the pretraining of AI models — not inference — but he attributed that more to where the AI world is today. He said that one day there will simply be more people running AI models, meaning more AI inference will happen. Huang noted that Nvidia is the largest inference platform in the world today and the company’s scale and reliability gives it a huge advantage compared to startups.

“Our hopes and dreams are that someday, the world does a ton of inference, and that’s when AI has really succeeded,” said Huang. “Everybody knows that if they innovate on top of CUDA and Nvidia’s architecture, they can innovate more quickly, and they know that everything should work.”",https://techcrunch.com/2024/11/20/nvidias-ceo-defends-his-moat-as-ai-labs-change-how-they-improve-their-ai-models/,"On its earnings call, analysts prodded CEO Jensen Huang about how Nvidia would fare if tech companies start using new methods to improve their AI models.Specifically, it adds more compute to the AI inference phase, which is everything that happens after a user hits enter on their prompt.However, Andreessen Horowitz partners and several other AI executives have previously said that these methods are already starting to show diminishing returns."
Why Nvidia investors are missing the forest for the trees,"Nvidia raked in more than $19 billion in net income during the last quarter, the company reported on Wednesday, but that did little to assure investors that its rapid growth would continue. On its earnings call, analysts prodded CEO Jensen Huang about how Nvidia would fare if tech companies start using new methods to improve their AI models.

The method that underpins OpenAI’s o1 model, or “test-time scaling,” came up quite a lot. It’s the idea that AI models will give better answers if you give them more time and computing power to “think” through questions. Specifically, it adds more compute to the AI inference phase, which is everything that happens after a user hits enter on their prompt.

Nvidia’s CEO was asked whether he was seeing AI model developers shift over to these new methods and how Nvidia’s older chips would work for AI inference.

Huang indicated that o1, and test-time scaling more broadly, could play a larger role in Nvidia’s business moving forward, calling it “one of the most exciting developments” and “a new scaling law.” Huang did his best to ensure investors that Nvidia is well-positioned for the change.

The Nvidia CEO’s remarks aligned with what Microsoft CEO Satya Nadella said onstage at a Microsoft event on Tuesday: o1 represents a new way for the AI industry to improve its models.

This is a big deal for the chip industry because it places a greater emphasis on AI inference. While Nvidia’s chips are the gold standard for training AI models, there’s a broad set of well-funded startups creating lightning-fast AI inference chips, such as Groq and Cerebras. It could be a more competitive space for Nvidia to operate in.

Despite recent reports that improvements in generative models are slowing, Huang told analysts that AI model developers are still improving their models by adding more compute and data during the pretraining phase.

Anthropic CEO Dario Amodei also said on Wednesday during an onstage interview at the Cerebral Valley summit in San Francisco that he is not seeing a slowdown in model development.

“Foundation model pretraining scaling is intact and it’s continuing,” said Huang on Wednesday. “As you know, this is an empirical law, not a fundamental physical law, but the evidence is that it continues to scale. What we’re learning, however, is that it’s not enough.”

That’s certainly what Nvidia investors wanted to hear, since the chipmaker’s stock has soared more than 180% in 2024 by selling the AI chips that OpenAI, Google, and Meta train their models on. However, Andreessen Horowitz partners and several other AI executives have previously said that these methods are already starting to show diminishing returns.

Huang noted that most of Nvidia’s computing workloads today are around the pretraining of AI models — not inference — but he attributed that more to where the AI world is today. He said that one day there will simply be more people running AI models, meaning more AI inference will happen. Huang noted that Nvidia is the largest inference platform in the world today and the company’s scale and reliability gives it a huge advantage compared to startups.

“Our hopes and dreams are that someday, the world does a ton of inference, and that’s when AI has really succeeded,” said Huang. “Everybody knows that if they innovate on top of CUDA and Nvidia’s architecture, they can innovate more quickly, and they know that everything should work.”",https://www.marketwatch.com/story/why-nvidia-investors-are-missing-the-forest-for-the-trees-5b39db56,"On its earnings call, analysts prodded CEO Jensen Huang about how Nvidia would fare if tech companies start using new methods to improve their AI models.Specifically, it adds more compute to the AI inference phase, which is everything that happens after a user hits enter on their prompt.However, Andreessen Horowitz partners and several other AI executives have previously said that these methods are already starting to show diminishing returns."
Hyundai unveils big electric SUV in fast-growing market,"Nvidia raked in more than $19 billion in net income during the last quarter, the company reported on Wednesday, but that did little to assure investors that its rapid growth would continue. On its earnings call, analysts prodded CEO Jensen Huang about how Nvidia would fare if tech companies start using new methods to improve their AI models.

The method that underpins OpenAI’s o1 model, or “test-time scaling,” came up quite a lot. It’s the idea that AI models will give better answers if you give them more time and computing power to “think” through questions. Specifically, it adds more compute to the AI inference phase, which is everything that happens after a user hits enter on their prompt.

Nvidia’s CEO was asked whether he was seeing AI model developers shift over to these new methods and how Nvidia’s older chips would work for AI inference.

Huang indicated that o1, and test-time scaling more broadly, could play a larger role in Nvidia’s business moving forward, calling it “one of the most exciting developments” and “a new scaling law.” Huang did his best to ensure investors that Nvidia is well-positioned for the change.

The Nvidia CEO’s remarks aligned with what Microsoft CEO Satya Nadella said onstage at a Microsoft event on Tuesday: o1 represents a new way for the AI industry to improve its models.

This is a big deal for the chip industry because it places a greater emphasis on AI inference. While Nvidia’s chips are the gold standard for training AI models, there’s a broad set of well-funded startups creating lightning-fast AI inference chips, such as Groq and Cerebras. It could be a more competitive space for Nvidia to operate in.

Despite recent reports that improvements in generative models are slowing, Huang told analysts that AI model developers are still improving their models by adding more compute and data during the pretraining phase.

Anthropic CEO Dario Amodei also said on Wednesday during an onstage interview at the Cerebral Valley summit in San Francisco that he is not seeing a slowdown in model development.

“Foundation model pretraining scaling is intact and it’s continuing,” said Huang on Wednesday. “As you know, this is an empirical law, not a fundamental physical law, but the evidence is that it continues to scale. What we’re learning, however, is that it’s not enough.”

That’s certainly what Nvidia investors wanted to hear, since the chipmaker’s stock has soared more than 180% in 2024 by selling the AI chips that OpenAI, Google, and Meta train their models on. However, Andreessen Horowitz partners and several other AI executives have previously said that these methods are already starting to show diminishing returns.

Huang noted that most of Nvidia’s computing workloads today are around the pretraining of AI models — not inference — but he attributed that more to where the AI world is today. He said that one day there will simply be more people running AI models, meaning more AI inference will happen. Huang noted that Nvidia is the largest inference platform in the world today and the company’s scale and reliability gives it a huge advantage compared to startups.

“Our hopes and dreams are that someday, the world does a ton of inference, and that’s when AI has really succeeded,” said Huang. “Everybody knows that if they innovate on top of CUDA and Nvidia’s architecture, they can innovate more quickly, and they know that everything should work.”",https://www.reuters.com/business/autos-transportation/hyundai-unveils-big-electric-suv-fast-growing-market-2024-11-21/,"On its earnings call, analysts prodded CEO Jensen Huang about how Nvidia would fare if tech companies start using new methods to improve their AI models.Specifically, it adds more compute to the AI inference phase, which is everything that happens after a user hits enter on their prompt.However, Andreessen Horowitz partners and several other AI executives have previously said that these methods are already starting to show diminishing returns."
Hyundai reveals all-electric Ioniq 9 three-row SUV,"Hyundai Motor's newest all-electric vehicle is the 2026 Ioniq 9 SUV — a three-row, up to seven-passenger SUV for the U.S. market.

The new vehicle is Hyundai's largest EV entry to date, joining the smaller Ioniq 5 and Ioniq 6 all-electric vehicles in the carmaker's growing fleet.

The Ioniq 9 is expected to arrive in U.S. dealerships in the spring. Hyundai said the vehicle will be capable of fast charging from 10% to 80% in 24 minutes, will have an estimated range of 335 miles on a single charge and will be able to achieve 0 to 60 miles per hour in as fast as 4.9 seconds.

Hyundai declined to disclose pricing for the new SUV until closer to its arrival in showrooms. The Kia EV9, from Hyundai's sister brand and which is based on the same vehicle platform, currently starts at around $55,000.",https://www.cnbc.com/2024/11/20/hyundai-ioniq-9-electric-three-row-suv.html,"Hyundai Motor's newest all-electric vehicle is the 2026 Ioniq 9 SUV — a three-row, up to seven-passenger SUV for the U.S. market.Hyundai said the vehicle will be capable of fast charging from 10% to 80% in 24 minutes, will have an estimated range of 335 miles on a single charge and will be able to achieve 0 to 60 miles per hour in as fast as 4.9 seconds.The Kia EV9, from Hyundai's sister brand and which is based on the same vehicle platform, currently starts at around $55,000."
Jazz Pharmaceuticals receives FDA approval for biliary tract cancer treatment,"Hyundai Motor's newest all-electric vehicle is the 2026 Ioniq 9 SUV — a three-row, up to seven-passenger SUV for the U.S. market.

The new vehicle is Hyundai's largest EV entry to date, joining the smaller Ioniq 5 and Ioniq 6 all-electric vehicles in the carmaker's growing fleet.

The Ioniq 9 is expected to arrive in U.S. dealerships in the spring. Hyundai said the vehicle will be capable of fast charging from 10% to 80% in 24 minutes, will have an estimated range of 335 miles on a single charge and will be able to achieve 0 to 60 miles per hour in as fast as 4.9 seconds.

Hyundai declined to disclose pricing for the new SUV until closer to its arrival in showrooms. The Kia EV9, from Hyundai's sister brand and which is based on the same vehicle platform, currently starts at around $55,000.",https://www.reuters.com/business/healthcare-pharmaceuticals/jazz-pharmaceuticals-receives-fda-approval-biliary-tract-cancer-treatment-2024-11-21/,"Hyundai Motor's newest all-electric vehicle is the 2026 Ioniq 9 SUV — a three-row, up to seven-passenger SUV for the U.S. market.Hyundai said the vehicle will be capable of fast charging from 10% to 80% in 24 minutes, will have an estimated range of 335 miles on a single charge and will be able to achieve 0 to 60 miles per hour in as fast as 4.9 seconds.The Kia EV9, from Hyundai's sister brand and which is based on the same vehicle platform, currently starts at around $55,000."
Reddit appears to be back after a 4-hour-long outage,"Social media platform Reddit experienced an outage this afternoon at around 12:20 p.m. PT (or possibly even earlier), resulting in thousands of users being unable to access its website and app. After four hours, it appears to be working again.

Reddit confirmed it fixed the issue and is monitoring the results, according to its status page.

We discovered the outage ourselves when attempting to visit the homepage, which displayed a black screen with the message: “Upstream connect error or disconnect/reset before headers. Reset reason: connection failure.” On the iOS app, we only saw the dead Snoo head, Reddit’s alien mascot.

Over 47,000 users reported problems on Downdetector.com and many users took to X to voice their complaints, sharing images of the same connection error page that we encountered.

TechCrunch has reached out to the company for comment.",https://techcrunch.com/2024/11/20/reddit-appears-to-be-back-after-a-4-hour-long-outage/,"Social media platform Reddit experienced an outage this afternoon at around 12:20 p.m. PT (or possibly even earlier), resulting in thousands of users being unable to access its website and app.Over 47,000 users reported problems on Downdetector.com and many users took to X to voice their complaints, sharing images of the same connection error page that we encountered.TechCrunch has reached out to the company for comment."
Nvidia says it will sell more of its next-generation Blackwell chips than previously anticipated,"NVIDIA founder, President and CEO Jensen Huang speaks about the future of artificial intelligence and its effect on energy consumption and production at the Bipartisan Policy Center on September 27, 2024 in Washington, DC.

After a quarter where Nvidia's sales nearly doubled, investors and analysts are wondering how long the chipmaker can keep this kind of growth going now that it has a $140 billion annual revenue run rate.

Those hopes fall on Blackwell, which is Nvidia's name for a family of server products based around its next-generation AI chip.

CEO Jensen Huang and CFO Colette Kress gave investors several new data points on how Blackwell's launch is shaping up on a call with analysts on Wednesday. The duo emphasized that the rollout is on track, and they signaled that Blackwell sales over the next few quarters will be limited by how many chips and systems Nvidia can make, not how much it can sell.

""Blackwell production is in full steam,"" Huang said. ""We will deliver this quarter more Blackwells than we had previously estimated.""

The company's positive comments on Blackwell are one reason why the stock is only down 1%, despite the company missing elevated expectations from bullish investors who anticipated Nvidia would significantly exceed its own forecasts.

Huang and Kress's comments also addressed fears about shipment delays that were spurred by reports that said Nvidia was making ongoing engineering changes to its systems to address problems.

Some of Nvidia's most important end-customers have already received some Blackwell chips, the company confirmed on Wednesday. Microsoft, Oracle and OpenAI have posted pictures of Blackwell-based server racks on their social media accounts, and on Wednesday, the company said 13,000 Blackwell chips have already been shipped to customers.

""There's still a lot of a lot of engineering that happens at this point,"" Huang said. ""But as you see from all of the systems that are being stood up, Blackwell is in great shape.""

Those sample chips aren't the bulk of the shipments that the company is expecting to make. They're early versions intended to allow customers to start testing and get their systems and software ready for the volume shipments, which will start in Nvidia's current quarter.

""We will we'll ship more Blackwells next quarter than this [quarter], and we'll ship more Blackwells the quarter after that than than our first quarter,"" Huang said.

In July, Nvidia said it expected ""several billion dollars"" of Blackwell revenue in its current quarter, and on Wednesday, the company said it expects the amount of Blackwell sales for this quarter to be higher than its original forecast. Huang also said that Microsoft will soon start to preview its Blackwell-based systems to cloud customers.

A limiting factor to producing more Blackwell systems is the amount of components that Nvidia's suppliers can provide, Huang said. Additionally, it takes time to ramp up the velocity of a manufacturing process that has gone from zero shipments to billions of dollars of shipments in a few months.

""It is the case that demand exceeds our supply, and that's expected as we're in the beginnings of this generative AI revolution,"" Huang said.

He also named some of Nvidia's ""great partners,"" including TSMC , Amphenol , Vertiv , SK Hynix and Micron .

""Almost every company in the world seems to be involved in our supply chain,"" Huang said.

Nvidia said that Blackwell's gross margins will be lower in the coming months than the 73.5% it reported in the third quarter, but the company said that margin will increase as the product matures. Huang pointed out that Blackwell comes as just the chip itself or in configurations that include an entire rack and other components.

Nvidia's overall message on Wednesday was that its new Blackwell chip is in short supply because companies like OpenAI need the fastest GPUs available as quickly as possible to develop next-generation AI models. As Blackwell rolls out, Nvidia's current AI chips, which it calls Hopper, will be relegated to serving AI models, not creating new ones. Nvidia said that Blackwell sales will eventually exceed those of Hopper.

""You see now that at the tail end of the last generation of foundation models, we're at at about 100,000 Hoppers,"" Huang said. ""The next generation starts at 100,000 Blackwells.""

WATCH: Nvidia can still grow even with Amazon and Microsoft entering the space: Susquehanna's Chris Rolland",https://www.cnbc.com/2024/11/20/nvidia-expects-to-sell-more-blackwell-chips-than-previously-anticipated.html,"Those hopes fall on Blackwell, which is Nvidia's name for a family of server products based around its next-generation AI chip.""But as you see from all of the systems that are being stood up, Blackwell is in great shape.""A limiting factor to producing more Blackwell systems is the amount of components that Nvidia's suppliers can provide, Huang said."
"Gold Edges Higher, Supported by Geopolitical Uncertainties","NVIDIA founder, President and CEO Jensen Huang speaks about the future of artificial intelligence and its effect on energy consumption and production at the Bipartisan Policy Center on September 27, 2024 in Washington, DC.

After a quarter where Nvidia's sales nearly doubled, investors and analysts are wondering how long the chipmaker can keep this kind of growth going now that it has a $140 billion annual revenue run rate.

Those hopes fall on Blackwell, which is Nvidia's name for a family of server products based around its next-generation AI chip.

CEO Jensen Huang and CFO Colette Kress gave investors several new data points on how Blackwell's launch is shaping up on a call with analysts on Wednesday. The duo emphasized that the rollout is on track, and they signaled that Blackwell sales over the next few quarters will be limited by how many chips and systems Nvidia can make, not how much it can sell.

""Blackwell production is in full steam,"" Huang said. ""We will deliver this quarter more Blackwells than we had previously estimated.""

The company's positive comments on Blackwell are one reason why the stock is only down 1%, despite the company missing elevated expectations from bullish investors who anticipated Nvidia would significantly exceed its own forecasts.

Huang and Kress's comments also addressed fears about shipment delays that were spurred by reports that said Nvidia was making ongoing engineering changes to its systems to address problems.

Some of Nvidia's most important end-customers have already received some Blackwell chips, the company confirmed on Wednesday. Microsoft, Oracle and OpenAI have posted pictures of Blackwell-based server racks on their social media accounts, and on Wednesday, the company said 13,000 Blackwell chips have already been shipped to customers.

""There's still a lot of a lot of engineering that happens at this point,"" Huang said. ""But as you see from all of the systems that are being stood up, Blackwell is in great shape.""

Those sample chips aren't the bulk of the shipments that the company is expecting to make. They're early versions intended to allow customers to start testing and get their systems and software ready for the volume shipments, which will start in Nvidia's current quarter.

""We will we'll ship more Blackwells next quarter than this [quarter], and we'll ship more Blackwells the quarter after that than than our first quarter,"" Huang said.

In July, Nvidia said it expected ""several billion dollars"" of Blackwell revenue in its current quarter, and on Wednesday, the company said it expects the amount of Blackwell sales for this quarter to be higher than its original forecast. Huang also said that Microsoft will soon start to preview its Blackwell-based systems to cloud customers.

A limiting factor to producing more Blackwell systems is the amount of components that Nvidia's suppliers can provide, Huang said. Additionally, it takes time to ramp up the velocity of a manufacturing process that has gone from zero shipments to billions of dollars of shipments in a few months.

""It is the case that demand exceeds our supply, and that's expected as we're in the beginnings of this generative AI revolution,"" Huang said.

He also named some of Nvidia's ""great partners,"" including TSMC , Amphenol , Vertiv , SK Hynix and Micron .

""Almost every company in the world seems to be involved in our supply chain,"" Huang said.

Nvidia said that Blackwell's gross margins will be lower in the coming months than the 73.5% it reported in the third quarter, but the company said that margin will increase as the product matures. Huang pointed out that Blackwell comes as just the chip itself or in configurations that include an entire rack and other components.

Nvidia's overall message on Wednesday was that its new Blackwell chip is in short supply because companies like OpenAI need the fastest GPUs available as quickly as possible to develop next-generation AI models. As Blackwell rolls out, Nvidia's current AI chips, which it calls Hopper, will be relegated to serving AI models, not creating new ones. Nvidia said that Blackwell sales will eventually exceed those of Hopper.

""You see now that at the tail end of the last generation of foundation models, we're at at about 100,000 Hoppers,"" Huang said. ""The next generation starts at 100,000 Blackwells.""

WATCH: Nvidia can still grow even with Amazon and Microsoft entering the space: Susquehanna's Chris Rolland",https://www.wsj.com/articles/gold-edges-higher-supported-by-geopolitical-uncertainties-4f4c06ba?mod=rss_markets_main,"Those hopes fall on Blackwell, which is Nvidia's name for a family of server products based around its next-generation AI chip.""But as you see from all of the systems that are being stood up, Blackwell is in great shape.""A limiting factor to producing more Blackwell systems is the amount of components that Nvidia's suppliers can provide, Huang said."
U.S. Plans to Propose Breakup of Google to Fix Search Monopoly,"The Justice Department and a group of states plan to ask a federal court late Wednesday to force Google to sell Chrome, its popular web browser, two people with knowledge of the decision said, a move that could fundamentally alter the $2 trillion company’s business and reshape competition on the internet.

The request would follow a landmark ruling in August by Judge Amit P. Mehta of the U.S. District Court for the District of Columbia that found Google had illegally maintained a monopoly in online search. Judge Mehta asked the Justice Department and the states that brought the antitrust case to submit solutions by the end of Wednesday to correct the search monopoly.

Beyond the sale of Chrome, the government is set to ask Judge Mehta to bar Google from entering into paid agreements with Apple and others to be the automatic search engine on smartphones and in browsers, the people said. Google should also be required to share data with rivals, they said.

The proposals would likely be the most significant remedies to be requested in a tech antitrust case since the Justice Department asked to break up Microsoft in 2000. If Judge Mehta adopts the proposals, they will set the tone for a string of other antitrust cases that challenge the dominance of tech behemoths including Apple, Amazon and Meta.",https://www.nytimes.com/2024/11/20/technology/google-search-remedies-doj.html,"The Justice Department and a group of states plan to ask a federal court late Wednesday to force Google to sell Chrome, its popular web browser, two people with knowledge of the decision said, a move that could fundamentally alter the $2 trillion company’s business and reshape competition on the internet.The request would follow a landmark ruling in August by Judge Amit P. Mehta of the U.S. District Court for the District of Columbia that found Google had illegally maintained a monopoly in online search.Google should also be required to share data with rivals, they said."
